Fundamentals are very important! Bigger picture focus.
Hype-Cycle for emerging tech usually starts from R&D till Mass media picks it up and hypes it at max.
Then the expectations fall, we get consolidation and failures till less than 5% of the audience fully adopt and we
    reach a neutral plateau.

First electronic programmable computers => World War 2, 1943 UK and 1945 US
US: Turing complete: General purpose machine. Ex - ENIAC Computer
UK: Turing Incomplete: Machine can only do one task. Ex - Colossus computer = Only break code.

ENIAC (Electronic Numerical Integrator and Calculator)
- 20, 10 digit registers (2 feet long each)
- Funded by US millitary, publicly disclosed in 1946 at University of Pennsylvania
- 18k vaccum tube 

The first transistor: 1947
First Integrated Circuit: 1958 with aim of integration of circuits
IC's were not flexible/programmable, thus we got ->
Microprocessor: 1971 where 3 projects gave 3 results
-> Intel -> Texas Instruments -> 
=> Performance improvement, feature size and clock speed with improvement in architecture to enable lightweight computers and 
    productivity based programming languages. RISC architecture's rose

RISC : Reduced Instruction Set Computer, CISC: Complex Instruction Set Computer
Numbers after the RISC are just different iterations.
Earlier, performance = Number of transistors, but now its Clock Speed.

Moores Law has 3 iterations:
Technologist (Spatial): Double transistors
Microarchitect (Temporal): Double Clock frequency per core
Multicore (Spatio-Temporal): Double cores per chip, Double parallelism per workload

It stopped now due to heat density : Amount of heat generated per unit area -> Led to Power War, Dennard's Scale
High heat density is due to transistor having so much current passed through it, it generates as much heat.
Characteristic Curve of the transistor: Slows down the switch of 1 to 0 or reverse in a transistor due to current.
Which consumes more and more power.
Solution was to have multicore chips (Parallelism)

Classes of computers
Personal Mobile Device (PMD) -> Smart Phone, Tablet computer
Desktop Computing -> Price-performance
Servers -> Availability, scalability, throughput
Clusters/Warehouse Scale Computers -> Used for SaaS, availability and price-performance.
    - Supercomputers (sub class), floating point performance
Embedded Computers: Components of system emphasis on price and real-time.

Flynn's Taxonomy:
Single Instruction stream, Single data stream   -> SISD [aka ILP Instruction Level Parallelism] (Uniprocessors)
Single Instruction stream, Multiple data stream -> SIMD [aka DLP Data Level Parallelism] (GPU's, Multimedia, Vector)
    Greyscale => 0 - 255, Black = 0, White = 255. Each pixel has 1 byte of color, so total pixels * bytes = Storage required.
    RGB => Frequency Bands, Color bands [Multiple colors = Multi spectral Image] Different bands in one Voxel.
    You need to allocate 3 times the memory for RGB than Greyscale. To process at same speed as greyscale, you use 3 PU's
        or processing units to process it at the same speed, hence SIMD.
    3 times speedup in SIMD vs SISD for RBG due to degree parallelism, which can process individual bands.
Multiple Instruction stream, Single data stream -> MISD (No commercial implementation, fault tolerance, maybe decryption
.                                                           by running multiple ciphers on one data stream/pool)
Multiple Instruction stream, Multiple data stream -> MIMD (Hyperthreading/VM)
    Tightly coupled MIMD -> TLP [Thread-level parallelism ]
    Loosely coupled MIMD -> RLP [Request-level parallelism]
    
Classes of Parallelism in application 
    Data Level Parallelism [DLP]
    Task Level Parallelism [TLP]

Computer architecture exploits DLP and TLP as
- Uniprocessor (single-core) architectures [Deep Parallelism]: ILP => DLP [Speculative Execution]
- Multiprocessor (multi-core) architecture [Wide Parallelism]:
    Vector architecture/GPU's   : DLP
    Thread Level Parallelism    : DLP/TLP
    Request Level Parallelism   : TLP

Defining Computer Architecture:
    -> Old is Instruction Set Architecture [ISA], i.e. decisions regarding registers, memory addressing, control flow instructions, etc.
    -> "Real" architecture is maximize performance with constraints or performance requirements of target.
    >       Includes ISA, hardware, organization.

Trends in Cost:
Cost driven down by learning curve (Yield)

Manufacturing IC's
Ingot --Slicer--> Wafer --20-40 processing steps--> Patterened Wafer --Dicer--> Tested Dies
Yield : Proportion of working dies per wafer = Working Dies/Dies per wafer
Approx 0.1 inch thick wafers from 24 inch Ingots ~ 240 wafers
IC cost increase if we have a lesser yield per wafer

Bose-Einstein formula (emperical model) to calculate Yield in advance.

Cerebras -> Computer system company, making Wafer-Scale Engine (WSE)
-> Largest chip built, 400000 AI-optimizied cores [46225mm^2, 2.1 Trillion Transistors]
-> 56 times the size of the Largest GPU [815mm^2 and 21.1 Billion Transistors]

WSE-2 : 2021
-> Largest chip built, improved, 850000 AI-optimizied cores [46225mm^2, 2.6 Trillion Transistors]

CPI for the process of calculations is average.
If different instruction classes, take different number of cycles. n_clockcycles = SUM(CPI_i x IC_i) where i
represents the i'th instruction.
Unaffected speedup in increasing the number of processors is the sequential vs parallel parts.
Maximum speedup is limited by the time of sequential parts.